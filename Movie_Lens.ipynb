{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input for the function to predict the ratings are as follows:\n",
    "\n",
    "    R - The user-movie rating matrix\n",
    "    K - Number of latent features\n",
    "    alpha - Learning rate of stochastic gradient descent\n",
    "    beta - Regularization parameter for bias\n",
    "    iterations - Number of iterations to perfrom stochastic gradient   descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#users\n",
    "u_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "users = pd.read_csv('ml-100k/u.user', sep='|', names = u_cols, encoding = 'latin-1' )\n",
    "\n",
    "#ratings\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "ratings = pd.read_csv('ml-100k/u.data', sep = '\\t', names = r_cols, encoding = 'latin-1')\n",
    "\n",
    "#items\n",
    "i_cols = ['movie id', 'movie title' ,'release date','video release date', 'IMDb URL', 'unknown', 'Action', 'Adventure',\n",
    "'Animation', 'Children\\'s', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy',\n",
    "'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
    "\n",
    "items = pd.read_csv('ml-100k/u.item', sep='|', names=i_cols, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((90570, 4), (9430, 4))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dividing the dataset into train and test, already done by grouplens before.\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "ratings_train = pd.read_csv('ml-100k/ua.base', sep='\\t', names=r_cols, encoding='latin-1')\n",
    "ratings_test = pd.read_csv('ml-100k/ua.test', sep='\\t', names=r_cols, encoding='latin-1')\n",
    "ratings_train.shape, ratings_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building user-user similarity and item-item similarity:\n",
    "\n",
    "#Calculates number of unique movie and users:\n",
    "n_users = ratings.user_id.unique().shape[0]\n",
    "n_items = ratings.movie_id.unique().shape[0]\n",
    "\n",
    "#Creating a user-data matrix:\n",
    "data_matrix = np.zeros((n_users, n_items))\n",
    "for line in ratings.itertuples():\n",
    "    #subtracting to make the starting index as 0 for the df.\n",
    "    data_matrix[line[1]-1, line[2]-1] = line[3]\n",
    "    \n",
    "#using pairwise function from sklearn to calculate cosine similarity:\n",
    "\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "user_similarity = pairwise_distances(data_matrix.T, metric = 'cosine')\n",
    "\n",
    "# I.E, the item-item and user-user is now in array form, now to make\n",
    "# predictions on these similarities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(ratings, similarity, type = 'user'):\n",
    "    if type == 'user':\n",
    "        mean_user_rating = ratings.mean(axis=1)\n",
    "        #Using np.newaxis to have same format as ratings\n",
    "        ratings_diff = (ratings - mean_user_rating[:, np.newaxis])\n",
    "        \n",
    "        # takes mean in column 1, then normalizing it with ratings_diff\n",
    "        # making predictions based on similarity of users\n",
    "        pred = mean_user_rating[:, np.newaxis] + similarity.dot(ratings_diff)/np.array([np.abs(similarity).sum(axis=1)]).T\n",
    "        \n",
    "    elif type == 'item':\n",
    "        # making predictions based on item similarity\n",
    "        pred = ratings.dot(similarity)/np.array([np.abs(similarity).sum(axis=1)])\n",
    "    return pred\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Warning: Ignoring columns timestamp;</pre>"
      ],
      "text/plain": [
       "Warning: Ignoring columns timestamp;"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>    To use these columns in scoring predictions, use a model that allows the use of additional features.</pre>"
      ],
      "text/plain": [
       "    To use these columns in scoring predictions, use a model that allows the use of additional features."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Preparing data set.</pre>"
      ],
      "text/plain": [
       "Preparing data set."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>    Data has 90570 observations with 943 users and 1680 items.</pre>"
      ],
      "text/plain": [
       "    Data has 90570 observations with 943 users and 1680 items."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>    Data prepared in: 0.139348s</pre>"
      ],
      "text/plain": [
       "    Data prepared in: 0.139348s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>90570 observations to process; with 1680 unique items.</pre>"
      ],
      "text/plain": [
       "90570 observations to process; with 1680 unique items."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Warning: Ignoring columns timestamp;</pre>"
      ],
      "text/plain": [
       "Warning: Ignoring columns timestamp;"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>    To use these columns in scoring predictions, use a model that allows the use of additional features.</pre>"
      ],
      "text/plain": [
       "    To use these columns in scoring predictions, use a model that allows the use of additional features."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Preparing data set.</pre>"
      ],
      "text/plain": [
       "Preparing data set."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>    Data has 90570 observations with 943 users and 1680 items.</pre>"
      ],
      "text/plain": [
       "    Data has 90570 observations with 943 users and 1680 items."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>    Data prepared in: 0.108078s</pre>"
      ],
      "text/plain": [
       "    Data prepared in: 0.108078s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Training model from provided data.</pre>"
      ],
      "text/plain": [
       "Training model from provided data."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Gathering per-item and per-user statistics.</pre>"
      ],
      "text/plain": [
       "Gathering per-item and per-user statistics."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+--------------------------------+------------+</pre>"
      ],
      "text/plain": [
       "+--------------------------------+------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Elapsed Time (Item Statistics) | % Complete |</pre>"
      ],
      "text/plain": [
       "| Elapsed Time (Item Statistics) | % Complete |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+--------------------------------+------------+</pre>"
      ],
      "text/plain": [
       "+--------------------------------+------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3.778ms                        | 100        |</pre>"
      ],
      "text/plain": [
       "| 3.778ms                        | 100        |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+--------------------------------+------------+</pre>"
      ],
      "text/plain": [
       "+--------------------------------+------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Setting up lookup tables.</pre>"
      ],
      "text/plain": [
       "Setting up lookup tables."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Processing data in one pass using dense lookup tables.</pre>"
      ],
      "text/plain": [
       "Processing data in one pass using dense lookup tables."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-------------------------------------+------------------+-----------------+</pre>"
      ],
      "text/plain": [
       "+-------------------------------------+------------------+-----------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Elapsed Time (Constructing Lookups) | Total % Complete | Items Processed |</pre>"
      ],
      "text/plain": [
       "| Elapsed Time (Constructing Lookups) | Total % Complete | Items Processed |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-------------------------------------+------------------+-----------------+</pre>"
      ],
      "text/plain": [
       "+-------------------------------------+------------------+-----------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 34.429ms                            | 19.5             | 330             |</pre>"
      ],
      "text/plain": [
       "| 34.429ms                            | 19.5             | 330             |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 152.931ms                           | 100              | 1680            |</pre>"
      ],
      "text/plain": [
       "| 152.931ms                           | 100              | 1680            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-------------------------------------+------------------+-----------------+</pre>"
      ],
      "text/plain": [
       "+-------------------------------------+------------------+-----------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finalizing lookup tables.</pre>"
      ],
      "text/plain": [
       "Finalizing lookup tables."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Generating candidate set for working with new users.</pre>"
      ],
      "text/plain": [
       "Generating candidate set for working with new users."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished training in 0.174273s</pre>"
      ],
      "text/plain": [
       "Finished training in 0.174273s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------------------+------+\n",
      "| user_id | movie_id |       score        | rank |\n",
      "+---------+----------+--------------------+------+\n",
      "|    1    |   423    | 0.9889649953550965 |  1   |\n",
      "|    1    |   202    | 0.9453457878291152 |  2   |\n",
      "|    1    |   655    | 0.7875979467657687 |  3   |\n",
      "|    1    |   403    | 0.7610751081058997 |  4   |\n",
      "|    1    |   568    | 0.7587905237237915 |  5   |\n",
      "|    2    |    50    | 1.1256258487701416 |  1   |\n",
      "|    2    |   181    | 1.0651773168490484 |  2   |\n",
      "|    2    |    7     | 0.9998190838557023 |  3   |\n",
      "|    2    |   121    | 0.9225130241650802 |  4   |\n",
      "|    2    |    9     | 0.831989913032605  |  5   |\n",
      "|    3    |   313    | 0.6353766620159149 |  1   |\n",
      "|    3    |   328    | 0.6032880300825293 |  2   |\n",
      "|    3    |   315    | 0.5422587123784152 |  3   |\n",
      "|    3    |   331    | 0.5355071858926252 |  4   |\n",
      "|    3    |   332    | 0.5316696112806146 |  5   |\n",
      "|    4    |    50    | 1.1311477082116264 |  1   |\n",
      "|    4    |   288    | 1.0487151145935059 |  2   |\n",
      "|    4    |   181    | 0.9505999386310577 |  3   |\n",
      "|    4    |    7     |  0.9417778807027   |  4   |\n",
      "|    4    |   302    | 0.9139021464756557 |  5   |\n",
      "|    5    |   195    | 0.9981269168131279 |  1   |\n",
      "|    5    |   202    | 0.9353599468866984 |  2   |\n",
      "|    5    |    56    | 0.8479394096316714 |  3   |\n",
      "|    5    |    82    |  0.74984691287532  |  4   |\n",
      "|    5    |   568    | 0.7362046353744738 |  5   |\n",
      "+---------+----------+--------------------+------+\n",
      "[25 rows x 4 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import turicreate \n",
    "\n",
    "# Creating SFrames for the testing datasets\n",
    "train_data = turicreate.SFrame(ratings_train)\n",
    "test_data = turicreate.SFrame(ratings_test)\n",
    "\n",
    "#Building a popularity model first:\n",
    "\n",
    "popularity_model = turicreate.popularity_recommender.create(train_data, user_id='user_id', item_id='movie_id', target= 'rating')\n",
    "\n",
    "#Recommending top 5 for first 5 users in dataset\n",
    "\n",
    "popularity_recomm = popularity_model.recommend(users=[1,2,3,4,5], k=5)\n",
    "#popularity_recomm.print_rows(num_rows=25)\n",
    "\n",
    "#Training the model\n",
    "\n",
    "item_sim_model = turicreate.item_similarity_recommender.create(train_data, user_id = 'user_id', item_id = 'movie_id', target = 'rating', similarity_type='cosine')\n",
    "\n",
    "#Making recommendations for first five users\n",
    "\n",
    "item_sim_recomm = item_sim_model.recommend(users = [1,2,3,4,5], k = 5)\n",
    "item_sim_recomm.print_rows(num_rows = 25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommendation engine using matrix factorization.\n",
    "# Defining a function to predict ratings givesn by the user to all movies \n",
    "# which are not rated by him.\n",
    "\n",
    "class MF():\n",
    "\n",
    "    #Initialising user-movie rating matrix, number of latent features, alpha and beta\n",
    "    \n",
    "    def __init__(self, R, K, alpha, beta, iterations):\n",
    "        \n",
    "        self.R = R\n",
    "        self.num_users, self.num_items = R.shape\n",
    "        self.K = K\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.iterations = iterations\n",
    "        \n",
    "        \n",
    "    # Initialising user-feature and movie-feature matrix\n",
    "    \n",
    "    def train(self):\n",
    "        self.P = np.random.normal(scale = 1./self.K, size = (self.num_users, self.K))\n",
    "        self.Q = np.random.normal(scale = 1./self.K, size = (self.num_items, self.K))\n",
    "        \n",
    "        # Initialising the bias terms\n",
    "        self.b_u = np.zeros(self.num_users) #Bias for users\n",
    "        self.b_i = np.zeros(self.num_items) #Bias for items\n",
    "        self.b = np.mean(self.R[np.where(self.R !=0)])\n",
    "        \n",
    "        \n",
    "        # Listing the training samples:\n",
    "        \n",
    "        self.samples = [\n",
    "            \n",
    "            (i,j,self.R[i,j]) for i in range(self.num_users) for j in range(self.num_items) if self.R[i,j]>0\n",
    "        ]\n",
    "    \n",
    "    \n",
    "        # Stochastic Gradient Descent for the given number of iterations:\n",
    "        \n",
    "        training_process = []\n",
    "        for i in range(self.iterations):\n",
    "            np.random.shuffle(self.samples)\n",
    "            self.sgd()\n",
    "            mse = self.mse()\n",
    "            training_process.append((i, mse))\n",
    "            if (i+1) %20 ==0:\n",
    "                print( \"Iteration %d ; error = %.4f\" %(i+1, mse))\n",
    "                \n",
    "        return training_process\n",
    "    \n",
    "    # Computing total mean squared error\n",
    "    \n",
    "    def mse(self):\n",
    "        xs, ys = self.R.nonzero()\n",
    "        predicted = self.full_matrix()\n",
    "        error = 0\n",
    "        for x,y in zip(xs, ys):\n",
    "            error += pow(self.R[x,y] - predicted[x,y], 2)\n",
    "        return np.sqrt(error)\n",
    "    \n",
    "    \n",
    "    # Stochastic gradient descent to get optimized for P and Q matrix\n",
    "    \n",
    "    def sgd(self):\n",
    "        for i, j, r in self.samples:\n",
    "            prediction = self.get_rating(i,j)\n",
    "            e = (r-prediction)\n",
    "            \n",
    "            self.b_u[i] += self.alpha * (e-self.beta * self.b_u[i])\n",
    "            self.b_i[j] += self.alpha * (e -self.beta *self.b_i[j])\n",
    "            \n",
    "            #Applying Update rule formula: \n",
    "            \n",
    "            self.P[i, :] += self.alpha * (e *self.Q[j,:] - self.beta * self.P[i,:])\n",
    "            self.Q[j, :] += self.alpha * (e * self.P[i, :] - self.beta * self.Q[j,:])\n",
    "            \n",
    "            \n",
    "            # Ratings for user i and movie J\n",
    "            \n",
    "    def get_rating(self, i, j):\n",
    "        prediction = self.b + self.b_u[i] + self.b_i[j] + self.P[i,:].dot(self.Q[j,:].T)\n",
    "\n",
    "        return prediction\n",
    "\n",
    "    #Full user-movie rating matrix:\n",
    "\n",
    "    def full_matrix(self):\n",
    "        return mf.b + mf.b_u[:, np.newaxis] + mf.b_i[np.newaxis:,] + mf.P.dot(mf.Q.T)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 20 ; error = 296.1239\n",
      "Iteration 40 ; error = 291.0511\n",
      "Iteration 60 ; error = 287.6236\n",
      "Iteration 80 ; error = 282.1210\n",
      "Iteration 100 ; error = 272.7766\n",
      "\n",
      "P x Q:\n",
      "[[3.87173935 3.20849117 3.18250684 ... 3.21319215 3.41689718 3.392433  ]\n",
      " [4.02106853 3.33504555 3.07825382 ... 3.37576922 3.48700197 3.45928026]\n",
      " [3.35671936 2.81725103 2.54100229 ... 2.8085876  2.94378619 2.89537766]\n",
      " ...\n",
      " [4.24866658 3.64129357 3.42182274 ... 3.63844248 3.75763916 3.72553688]\n",
      " [4.37788464 3.81243214 3.5181269  ... 3.77406148 3.922746   3.88887523]\n",
      " [3.91898823 3.30608576 2.89804956 ... 3.24965891 3.34111298 3.36158185]]\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Converting the user-item ratings to matrix form. \n",
    "\n",
    "R = np.array(ratings.pivot(index = 'user_id', columns = 'movie_id', values = 'rating').fillna(0))\n",
    "\n",
    "\n",
    "# Predicting all missing ratings. \n",
    "# K = 20, alpha = 0.001, beta = 0.01, iterations = 100\n",
    "\n",
    "mf = MF(R, K=20, alpha = 0.001, beta = 0.01, iterations = 100)\n",
    "training_process = mf.train()\n",
    "print()\n",
    "print(\"P x Q:\")\n",
    "print(mf.full_matrix())\n",
    "print()\n",
    "print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
